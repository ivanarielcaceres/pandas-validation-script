{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from files.validations.sales_transactional_other import SALES_TRANSACTIONAL_OTHER_VALIDATION\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all files in Sales transactional directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME_PATTERN = 'YY_MM_SALES_OTH_MX.CSV'\n",
    "files = os.listdir('files/outbound/it/sales_transactional')\n",
    "files = list(filter(lambda x: bool(re.match('\\d{2}_\\d{2}_SALES_OTH_MX.CSV', x)), files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to validate each row on the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_row(row):\n",
    "    global results\n",
    "    for index, val in row.iteritems():\n",
    "        logger.debug('Column: {}'.format(row.name))\n",
    "        logger.debug('Value: {}'.format(str(val)))\n",
    "        logger.debug('Data type: {}'.format(type(val)))\n",
    "        logger.debug('Row: {}'.format(index))\n",
    "        \n",
    "        # If the filed is empty (NaN or None) and the field validation is not required, continue for the next loop\n",
    "        if ((type(val) is float and math.isnan(val)) or (val is None)) \\\n",
    "            and (validation_df.loc['required'][row.name] is not True):\n",
    "            logger.debug('The field is empty and the filed validation is not required, ...')\n",
    "            continue\n",
    "            \n",
    "        # If the filed is empty (NaN or None) and the field validation is required, insert column and row and continue for the next loop\n",
    "        if ((type(val) is float and math.isnan(val)) or (val is None)) \\\n",
    "            and (validation_df.loc['required'][row.name] is True):\n",
    "            logger.debug('ERROR required')\n",
    "            results[1].add('required')\n",
    "            results[2].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "            continue\n",
    "            \n",
    "         \n",
    "        #CHECK FOR LENGTH ERRORS FOR STR        \n",
    "        if type(val) is str:\n",
    "            if (validation_df.loc['data_type_length'][row.name] and len(val) > validation_df.loc['data_type_length'][row.name]):\n",
    "                logger.debug('ERROR data_type_length length')\n",
    "                results[1].add('data_type_length')\n",
    "                results[2].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "                \n",
    "            if (validation_df.loc['min_length'][row.name] and len(val) < validation_df.loc['min_length'][row.name]):\n",
    "                logger.debug('ERROR min_length length')\n",
    "                results[1].add('min_length')\n",
    "                results[2].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "            \n",
    "            if (validation_df.loc['max_length'][row.name] and len(val) > validation_df.loc['max_length'][row.name]):\n",
    "                logger.debug('ERROR max_length length')\n",
    "                results[1].add('max_length')\n",
    "                results[2].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "          \n",
    "            if (validation_df.loc['exact_length'][row.name] and len(val) != validation_df.loc['exact_length'][row.name]):\n",
    "                    logger.debug('ERROR exact_length length')\n",
    "                    results[1].add('exact_length')\n",
    "                    results[2].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "\n",
    "        \n",
    "        # CHECK FOR DATATYPE ERRORS\n",
    "        # datatype\n",
    "        if validation_df.loc['data_type'][row.name] and type(val) is not validation_df.loc['data_type'][row.name]:     \n",
    "            logger.debug('ERROR validation datatype')\n",
    "            results[1].add('data_type')\n",
    "            results[3].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "            \n",
    "        # only_number \n",
    "        if validation_df.loc['only_numbers'][row.name] and validation_df.loc['only_numbers'][row.name] is True and not str(val).isdigit():     \n",
    "            logger.debug('ERROR validation only_numbers')\n",
    "            results[1].add('only_numbers')\n",
    "            results[3].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "            \n",
    "        #only_char\n",
    "        if validation_df.loc['only_chars'][row.name] and validation_df.loc['only_chars'][row.name] is True and not bool(re.match('^[a-zA-Z]+$', str(val))):     \n",
    "            logger.debug('ERROR validation only_chars')\n",
    "            results[1].add('only_chars')\n",
    "            results[3].append('Column: {}, Row: {}'.format(row.name, index))\n",
    "            \n",
    "        # CHECK FOR PATTERN ERRORS\n",
    "        # datatype\n",
    "        #if validation_df.loc['pattern'][row.name]:     \n",
    "            #print('ERROR validation pattern')\n",
    "            #results[4].append('Column: {}, Row: {}'.format(row.name, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over each files and do validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_in_chunk(file):\n",
    "    mylist = []\n",
    "    for chunk in  pd.read_csv('files/outbound/it/sales_transactional/{}'.format(file), sep='|', chunksize=20000, converters={'/BIC/HMMATPAD': lambda x: str(x)}):\n",
    "        mylist.append(chunk)\n",
    "    df = pd.concat(mylist, axis= 0)\n",
    "    del mylist\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[['Your file does not have errors'], set(), ['Your file does not have Length errors'], ['Your file does not have Data type errors'], []]\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    validation_df = pd.DataFrame.from_dict(SALES_TRANSACTIONAL_OTHER_VALIDATION)\n",
    "    df = retrieve_in_chunk(file)\n",
    "    df.replace(r'\\s+', np.nan, regex=True, inplace=True)\n",
    "    check = []\n",
    "    n_check = set()\n",
    "    l_check = []\n",
    "    t_check = []\n",
    "    p_check = []\n",
    "    results = [check, n_check, l_check, t_check, p_check]\n",
    "    df.head(5).apply(lambda x: validate_row(x))\n",
    "    if len(results[2]) > 0:\n",
    "        results[2].insert(0, 'Your file contains: {} Length errors'.format(len(results[2])))\n",
    "    else:\n",
    "        results[2].insert(0, 'Your file does not have Length errors')\n",
    "\n",
    "    if len(results[3]) > 0:\n",
    "        results[3].insert(0, 'Your file contains: {} Datatype errors'.format(len(results[3])))\n",
    "    else:\n",
    "        results[3].insert(0, 'Your file does not have Data type errors')\n",
    "\n",
    "    # If n_check, l_check, t_check or p_check is greater than 1, then the files has errors \n",
    "    if len(results[1]) > 1 or len(results[2]) > 1 or len(results[3]) > 1 or len(results[4]) > 1:\n",
    "        results[0].insert(0, 'The file {} has errors'.format(file))\n",
    "    else:\n",
    "        results[0].insert(0, 'Your file does not have errors')    \n",
    "        \n",
    "    logger.warning(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
